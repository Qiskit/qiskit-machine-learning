{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equivalent-affiliate",
   "metadata": {},
   "source": [
    "# Torch Connector\n",
    "\n",
    "This tutorial shows how the `TorchConnector` allows to use any `NeuralNetwork` from Qiskit Machine Learning and integrate it in a PyTorch workflow. The `TorchConnector` takes any `NeuralNetwork` and makes it available as a PyTorch `Module`.\n",
    "\n",
    "### Content:\n",
    "\n",
    "#### Part 1: Simple Classification & Regression\n",
    "- Classification\n",
    "    - Classification with PyTorch and the `OpflowQNN`\n",
    "    - Classification with PyTorch and the `CircuitQNN`\n",
    "- Regression\n",
    "    - Regression with PyTorch and the `OpflowQNN`\n",
    "\n",
    "#### Part 2: MNIST Classification\n",
    "\n",
    "Illustrates how to embed a (Quantum) `NeuralNetwork` into a larget PyTorch workflow to classify MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indirect-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-laundry",
   "metadata": {},
   "source": [
    "# Part 1: Simple Classification & Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-beverage",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "First, we show how the `TorchConnector` can be used to use a Quantum `NeuralNetwork` to solve a classification tasks. Therefore, we generate a simple random data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuffed-quantity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "num_samples = 20\n",
    "X = 2*np.random.rand(num_samples, num_inputs) - 1\n",
    "y01 = 1*(np.sum(X, axis=1) >= 0)  # in { 0,  1}\n",
    "y = 2*y01-1                       # in {-1, +1}\n",
    "\n",
    "X_ = Tensor(X)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "\n",
    "for x, y_target in zip(X, y):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "plt.plot([-1, 1], [1, -1], '--', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-stream",
   "metadata": {},
   "source": [
    "### Classification with PyTorch and the `OpflowQNN`\n",
    "\n",
    "Linking an `OpflowQNN` to PyTorch is relatively straight-forward. Here we illustrate this using the `TwoLayerQNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excellent-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up QNN\n",
    "qnn1 = TwoLayerQNN(num_qubits=num_inputs, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn1.num_weights) - 1)\n",
    "model1 = TorchConnector(qnn1, initial_weights=initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secure-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2949], grad_fn=<_TorchNNFunctionBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with a single input\n",
    "model1(X_[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.592493057250977\n",
      "17.31513214111328\n",
      "17.475332260131836\n",
      "16.81917953491211\n",
      "16.67049217224121\n"
     ]
    }
   ],
   "source": [
    "# define optimizer and loss\n",
    "optimizer = LBFGS(model1.parameters())\n",
    "f_loss = MSELoss(reduction='sum')\n",
    "\n",
    "# start training\n",
    "model1.train()   # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()          # initialize gradient\n",
    "    loss = f_loss(model1(X_), y_)  # evaluate loss function\n",
    "    loss.backward()                # backward pass\n",
    "    print(loss.item())             # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x, y_target in zip(X, y):\n",
    "    output = model1(Tensor(x))\n",
    "    y_predict += [np.sign(output.detach().numpy())[0]]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == y)/len(y))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_p in zip(X, y, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_p:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.plot([-1, 1], [1, -1], '--', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-berry",
   "metadata": {},
   "source": [
    "The red circles indicate wrongly classified data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-solid",
   "metadata": {},
   "source": [
    "### Classification with PyTorch and the `CircuitQNN`\n",
    "\n",
    "Linking an `CircuitQNN` to PyTorch requires the correct setup, otherwise backpropagation is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = ZZFeatureMap(num_inputs)\n",
    "var_form = RealAmplitudes(num_inputs, entanglement='linear', reps=1)\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(var_form, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=var_form.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad(set_to_none=True)                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == y01)/len(y01))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.plot([-1, 1], [1, -1], '--', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-family",
   "metadata": {},
   "source": [
    "## Regression \n",
    "\n",
    "We use a model based on the `TwoLayerQNN` to also illsutrate an regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "eps = 0.2\n",
    "lb, ub = -np.pi, np.pi\n",
    "f = lambda x: np.sin(x)\n",
    "\n",
    "X = (ub - lb)*np.random.rand(num_samples, 1) + lb\n",
    "y = f(X) + eps*(2*np.random.rand(num_samples, 1)-1)\n",
    "plt.plot(np.linspace(lb, ub), f(np.linspace(lb, ub)), 'r--')\n",
    "plt.plot(X, y, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct simple feature map\n",
    "param_x = Parameter('x')\n",
    "feature_map = QuantumCircuit(1, name='fm')\n",
    "feature_map.ry(param_x, 0)\n",
    "\n",
    "# construct simple feature map\n",
    "param_y = Parameter('y')\n",
    "var_form = QuantumCircuit(1, name='vf')\n",
    "var_form.ry(param_y, 0)\n",
    "\n",
    "# construct QNN\n",
    "qnn3 = TwoLayerQNN(1, feature_map, var_form, quantum_instance=qi)\n",
    "print(qnn3.operator)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn3.num_weights) - 1)\n",
    "model3 = TorchConnector(qnn3, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "optimizer = LBFGS(model3.parameters())\n",
    "f_loss = MSELoss(reduction='sum')\n",
    "\n",
    "# start training\n",
    "model3.train()   # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad(set_to_none=True)        # initialize gradient\n",
    "    loss = f_loss(model3(Tensor(X)), Tensor(y))  # compute batch loss\n",
    "    loss.backward()                              # backward pass    \n",
    "    print(loss.item())                           # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target function\n",
    "plt.plot(np.linspace(lb, ub), f(np.linspace(lb, ub)), 'r--')\n",
    "\n",
    "# plot data\n",
    "plt.plot(X, y, 'bo')\n",
    "\n",
    "# plot fitted line\n",
    "y_ = []\n",
    "for x in np.linspace(lb, ub):\n",
    "    output = model3(Tensor([x]))\n",
    "    y_ += [output.detach().numpy()[0]]\n",
    "plt.plot(np.linspace(lb, ub), y_, 'g-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-fifth",
   "metadata": {},
   "source": [
    "# Part 2: MNIST Example \n",
    "Also see Qiskit Textbook: https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cat, no_grad \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss, \n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concentrating on the first 100 samples\n",
    "batch_size = 1\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0, 0].numpy().squeeze(), cmap='gray')\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets[0].item()))\n",
    "    \n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define QNN\n",
    "feature_map = ZZFeatureMap(2)\n",
    "var_form = RealAmplitudes(2, reps=1)\n",
    "qnn4 = TwoLayerQNN(2, feature_map, var_form, exp_val=AerPauliExpectation(), quantum_instance=qi)\n",
    "print(qnn4.operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)\n",
    "        self.fc2 = Linear(64, 1)         # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn4)  # \n",
    "        self.fc3 = Linear(1, 1)          # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return cat((x, 1 - x), -1)\n",
    "    \n",
    "model4 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model, optimizer, and loss function\n",
    "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "# start training\n",
    "epochs = 10     # set number of epochs\n",
    "loss_list = []  # store loss history\n",
    "model4.train()  # set model to training mode\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):        \n",
    "        optimizer.zero_grad(set_to_none=True)  # initialize gradient\n",
    "        output = model4(data)                   # forward pass\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "        loss = loss_func(output, target)       # calculate loss\n",
    "        loss.backward()                        # backward pass\n",
    "        optimizer.step()                       # optimize weights\n",
    "        total_loss.append(loss.item())         # store loss    \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))    \n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg. Log Likelihood Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.eval()  # set model to evaluation mode\n",
    "with no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model4(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'\n",
    "          .format(sum(total_loss) / len(total_loss), \n",
    "                  correct / len(test_loader) / batch_size * 100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model4.eval()\n",
    "with no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model4(data[0:1])\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "%qiskit_version_table\n",
    "%qiskit_copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
